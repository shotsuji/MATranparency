rownames(duplicated(ma_data$Citation))
#some validity checks
ma_data$Citation[duplicated(ma_data$Citation) == TRUE]
#some validity checks
ma_data[duplicated(ma_data$Citation) == TRUE]
#some validity checks
ma_data[duplicated(ma_data$Citation) == TRUE,]
table(ma_data$Citation)
duplicated(ma_data$Citation)
#some validity checks
ma_data[duplicated(ma_data$Citation) == TRUE,]
table(ma_data$Coder)
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
#some validity checks (most are not pertinent anymore)
ma_data[duplicated(ma_data$Citation) == TRUE,] #this showed 3 duplicates in original sheet - checked and moved duplicates to duplicates sheet in google sheet with documentation
ma_data[duplicated(ma_data$Citation) == TRUE,]
table(ma_data$Coder) #this shows that ST has 2, and EH 6 records more than required
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
ma_data = read.csv(textConnection(url), skip =1)
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
groups = c(rep(groups[5],3*167),rep(groups[8],7*167),rep(groups[15],4*167),
rep(groups[19],3*167),rep(groups[22],5*167),rep(groups[27],1*167),rep(groups[28],3*167),rep(groups[31],5*167),rep(groups[36],3*167))
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
groups
colnames(read.csv(textConnection(url)))
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
groups
ma_data = read.csv(textConnection(url), skip =1)
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
groups
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
groups
url
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(RCurl)
library(ggplot2)
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
#some validity checks (not pertinent anymore since dealt with)
#ma_data[duplicated(ma_data$Citation) == TRUE,] #this showed 3 duplicates in original sheet - checked and moved duplicates to duplicates sheet in google sheet with documentation
#table(ma_data$Coder) #this shows that ST has 1, and EH 4 records more than required. ST simply coded one too much & this was moved to additional_codings sheet. EH had to MAs based on 3 separate searches each and therefore has 3 instead of 2 1 rows twice, leading to the 4 additional rows
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
grpoups
groups
groups = c(rep(groups[5],3*167),rep(groups[8],7*167),rep(groups[15],4*167),
rep(groups[19],3*167),rep(groups[22],5*167),rep(groups[27],1*167),rep(groups[28],3*167),rep(groups[31],5*167),rep(groups[36],3*167),rep("comments",2*167))
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
dim(ma_data)[1]
length_ma = dim(ma_data)[1]
groups = c(rep(groups[5],3*length_ma),rep(groups[8],7*length_ma),rep(groups[15],4*length_ma),
rep(groups[19],3*length_ma),rep(groups[22],5*length_ma),rep(groups[27],1*length_ma),rep(groups[28],3*length_ma),rep(groups[31],5*length_ma),rep(groups[36],3*length_ma),rep("comments",2*length_ma))
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
5544-5390
groups
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
#mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
View(ma_data_long)
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
groups
length_ma = dim(ma_data)[1]
groups = c(rep(groups[5],3*length_ma),rep(groups[8],7*length_ma),rep(groups[15],4*length_ma),
rep(groups[19],3*length_ma),rep(groups[22],5*length_ma),rep(groups[27],1*length_ma),rep(groups[28],3*length_ma),rep(groups[31],5*length_ma),rep(groups[36],2*length_ma),rep("comments",2*length_ma))
#put into long format and recode
ma_data_long <- ma_data %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
#overall summary
ma_data_sum_all <- ma_data_long %>%
filter(value == "n" | value == "y" ) %>%
group_by(value, Citation) %>%
summarise(n = n())
ma_data_sum_all_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(Citation,x) %>%
summarise(pc = mean(value_num))
#summary by topic
#bigger cats, and best and worst columns
#relationships: correlation between funding, type of MA
#scrape title word cloud
ma_data_sum_bytopic <- ma_data_long %>%
filter(value == "n" | value == "y" ) %>%
group_by(value,value_num,groups,Citation) %>%
summarise(n = n())
ma_data_sum_bytopic_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(groups,Citation,x) %>%
summarise(pc = mean(value_num))
#summary by year
ma_data_sum_byyear <- ma_data_long %>%
filter(value == "n" | value == "y" ) %>%
filter(!is.na(year)) %>%
group_by(value,value_num,year,Citation) %>%
summarise(n = n())
ma_data_sum_byyear_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
filter(!is.na(year)) %>%
group_by(year,Citation,x) %>%
summarise(pc = mean(value_num))
#overall
# ma_data_sum_all_plot = ggplot(ma_data_sum_all, aes(x = value, y = n, fill = value))+
#   geom_boxplot() +
#   scale_fill_manual(values = c("lightblue","darkblue"))+
#   theme_light(base_size = 15) +
#   theme(legend.position="none") +
#   xlab("Reported")+
#   ylab("Count by paper")+
#   ggtitle("Reported overall")
# ma_data_sum_all_plot
# ggsave("ma_data_sum_all_plot.png",ma_data_sum_all_plot, height = 5, width = 5, units = "in" )
ma_data_sum_all_pc_plot = ggplot(ma_data_sum_all_pc, aes(y = pc,x = x))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_sum_all_pc_plot
ggsave("ma_data_sum_all_pc_plot.png",ma_data_sum_all_pc_plot, height = 5, width = 5, units = "in" )
#by theme
ma_data_sum_bytopic_pc_plot = ggplot(ma_data_sum_bytopic_pc, aes(y = pc, x = x))+
facet_wrap("groups") +
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported by topic")
ma_data_sum_bytopic_pc_plot
ggsave("ma_data_sum_bytopic_pc_plot.png",ma_data_sum_bytopic_pc_plot, height = 5, width = 5, units = "in" )
#by year
ma_data_sum_byyear_pc_plot = ggplot(ma_data_sum_byyear_pc, aes(y = pc, x = x))+
facet_wrap("year") +
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported by year")
ma_data_sum_byyear_pc_plot
ggsave("ma_data_sum_byyear_pc_plot.png",ma_data_sum_byyear_pc_plot, height = 5, width = 5, units = "in" )
View(ma_data_sum_all)
View(ma_data_sum_all_pc)
View(ma_data_sum_bytopic_pc)
View(ma_data_long)
table(ma_data_long$value)
View(ma_data)
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-"Eligibility...Design.record")
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-"Eligibility...Design.record","Comments")
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-"Eligibility...Design.record","Comments")
#remove columns not needed for ana
ma_data_ana = ma_data %>%
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-c(Eligibility...Design.record,Comments))
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-c(Eligibility...Design.record,Comments))
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-c(Eligibility...Design.record,Comments,Response))
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
length_ma = dim(ma_data_ana)[1]
groups = c(rep(groups[5],3*length_ma),rep(groups[8],6*length_ma),rep(groups[15],4*length_ma),
rep(groups[19],3*length_ma),rep(groups[22],5*length_ma),rep(groups[27],1*length_ma),rep(groups[28],3*length_ma),rep(groups[31],5*length_ma),rep(groups[36],2*length_ma))
#put into long format and recode
ma_data_long <- ma_data_ana %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
View(ma_data_long)
#put into long format and recode
ma_data_long <- ma_data_ana %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1, "correlation" = 1, "experimental " = 1, "group differences" = 1
)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
View(ma_data_long)
#put into long format and recode
ma_data_long <- ma_data_ana %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1, "correlation" = 1, "experimental" = 1, "group differences" = 1
)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
View(ma_data_long)
ma_data_sum_all_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(Citation,x) %>%
summarise(pc = mean(value_num))
ma_data_sum_bytopic_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(groups,Citation,x) %>%
summarise(pc = mean(value_num))
ma_data_sum_byyear_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
filter(!is.na(year)) %>%
group_by(year,Citation,x) %>%
summarise(pc = mean(value_num))
#overall
# ma_data_sum_all_plot = ggplot(ma_data_sum_all, aes(x = value, y = n, fill = value))+
#   geom_boxplot() +
#   scale_fill_manual(values = c("lightblue","darkblue"))+
#   theme_light(base_size = 15) +
#   theme(legend.position="none") +
#   xlab("Reported")+
#   ylab("Count by paper")+
#   ggtitle("Reported overall")
# ma_data_sum_all_plot
# ggsave("ma_data_sum_all_plot.png",ma_data_sum_all_plot, height = 5, width = 5, units = "in" )
ma_data_sum_all_pc_plot = ggplot(ma_data_sum_all_pc, aes(y = pc,x = x))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_sum_all_pc_plot
ggsave("ma_data_sum_all_pc_plot.png",ma_data_sum_all_pc_plot, height = 5, width = 5, units = "in" )
#by theme
ma_data_sum_bytopic_pc_plot = ggplot(ma_data_sum_bytopic_pc, aes(y = pc, x = x))+
facet_wrap("groups") +
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported by topic")
ma_data_sum_bytopic_pc_plot
ggsave("ma_data_sum_bytopic_pc_plot.png",ma_data_sum_bytopic_pc_plot, height = 5, width = 5, units = "in" )
#by year
ma_data_sum_byyear_pc_plot = ggplot(ma_data_sum_byyear_pc, aes(y = pc, x = x))+
facet_wrap("year") +
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported by year")
ma_data_sum_byyear_pc_plot
ggsave("ma_data_sum_byyear_pc_plot.png",ma_data_sum_byyear_pc_plot, height = 5, width = 5, units = "in" )
View(ma_data_sum_byyear_pc)
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
#some validity checks (not pertinent anymore since dealt with)
#ma_data[duplicated(ma_data$Citation) == TRUE,] #this showed 3 duplicates in original sheet - checked and moved duplicates to duplicates sheet in google sheet with documentation
#table(ma_data$Coder) #this shows that ST has 1, and EH 4 records more than required. ST simply coded one too much & this was moved to additional_codings sheet. EH had to MAs based on 3 separate searches each and therefore has 3 instead of 2 1 rows twice, leading to the 4 additional rows
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-c(Eligibility...Design.record,Comments,Response))
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
length_ma = dim(ma_data_ana)[1]
groups = c(rep(groups[5],3*length_ma),rep(groups[8],6*length_ma),rep(groups[15],4*length_ma),
rep(groups[19],3*length_ma),rep(groups[22],5*length_ma),rep(groups[27],1*length_ma),rep(groups[28],3*length_ma),rep(groups[31],5*length_ma),rep(groups[36],2*length_ma))
#put into long format and recode
ma_data_long <- ma_data_ana %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1, "correlation" = 1, "experimental" = 1, "group differences" = 1
)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
#overall summary
# ma_data_sum_all <- ma_data_long %>%
#   filter(value == "n" | value == "y" ) %>%
#   group_by(value, Citation) %>%
#   summarise(n = n())
ma_data_sum_all_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(Citation,x) %>%
summarise(pc = mean(value_num))
#summary by topic
#bigger cats, and best and worst columns
#relationships: correlation between funding, type of MA
#scrape title word cloud
# ma_data_sum_bytopic <- ma_data_long %>%
#  filter(value == "n" | value == "y" ) %>%
#   group_by(value,value_num,groups,Citation) %>%
#   summarise(n = n())
ma_data_sum_bytopic_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(groups,Citation,x) %>%
summarise(pc = mean(value_num))
#summary by year
# ma_data_sum_byyear <- ma_data_long %>%
#  filter(value == "n" | value == "y" ) %>%
#   filter(!is.na(year)) %>%
#   group_by(value,value_num,year,Citation) %>%
#   summarise(n = n())
ma_data_sum_byyear_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
filter(!is.na(year)) %>%
group_by(year,Citation,x) %>%
summarise(pc = mean(value_num))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(RCurl)
library(ggplot2)
#read in data
url = getURL("https://docs.google.com/spreadsheets/d/e/2PACX-1vRSq8M2OV53eK1Mt99hxjnUcinfZuA5poxKPPPtN5bv12gKfiz_DHvhHHHbbjuzpINWM-jGvRBxrANg/pub?gid=0&single=true&output=csv")
ma_data = read.csv(textConnection(url), skip =1)
#remove columns not needed for ana
ma_data_ana = ma_data %>%
select(-c(Eligibility...Design.record,Comments,Response))
#get first row from google sheet for grouping (sry quite manual)
groups = colnames(read.csv(textConnection(url)))
length_ma = dim(ma_data_ana)[1]
groups = c(rep(groups[5],3*length_ma),rep(groups[8],6*length_ma),rep(groups[15],4*length_ma),
rep(groups[19],3*length_ma),rep(groups[22],5*length_ma),rep(groups[27],1*length_ma),rep(groups[28],3*length_ma),rep(groups[31],5*length_ma),rep(groups[36],2*length_ma))
#put into long format and recode
ma_data_long <- ma_data_ana %>%
gather(criterion, value, -c(Coder:DOI)) %>%
mutate(value_num = recode(value, "n" = 0, "y" = 1, "correlation" = 1, "experimental" = 1, "group differences" = 1
)) %>%
mutate(groups = groups) %>%
mutate(year = case_when(DoP >=1990 & DoP < 2000 ~ 1990,
DoP >=2000 & DoP < 2010 ~ 2000,
DoP >=2010 ~ 2010)) %>%
mutate(x = 1)
ma_data_sum_all_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(Citation,x) %>%
summarise(pc = mean(value_num))
ma_data_sum_bytopic_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(groups,Citation,x) %>%
summarise(pc = mean(value_num))
ma_data_sum_byyear_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
filter(!is.na(year)) %>%
group_by(year,Citation,x) %>%
summarise(pc = mean(value_num))
View(ma_data_sum_byyear_pc)
min(ma_data_sum_byyear_pc$pc)
ma_data_sum_byyear_pc$[(ma_data_sum_byyear_pc$pc == min(ma_data_sum_byyear_pc$pc)]
ma_data_sum_byyear_pc[(ma_data_sum_byyear_pc$pc == min(ma_data_sum_byyear_pc$pc)]
ma_data_sum_byyear_pc[ma_data_sum_byyear_pc$pc == min(ma_data_sum_byyear_pc$pc)]
#percentage by colums
ma_data_bycolum_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(criterion,x) %>%
summarise(pc = mean(value_num))
View(ma_data_sum_all_pc)
View(ma_data_bycolum_pc)
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
View(ma_data_all_pc_plot)
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none"+axis.text.x = element_text(angle = 90, hjust = 1)) +
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none"+ axis.text.x = element_text(angle = 90, hjust = 1)) +
+ theme(axis.text.x = element_text(angle = 90, hjust = 1))+
ylab("Percentage reported")+
ggtitle("Reported overall")
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 90))+
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
facet_wrap("groups")+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
#percentage by colums
ma_data_bycolum_pc <- ma_data_long %>%
filter(value_num == 0 | value_num == 1 ) %>%
group_by(groups,criterion,x) %>%
summarise(pc = mean(value_num))
#all separate
ma_data_all_pc_plot = ggplot(ma_data_bycolum_pc, aes(y = pc,x = criterion))+
facet_wrap("groups")+
geom_boxplot() +
geom_jitter(width = 0.1,height = 0, aes(alpha = 0.5,col = "blue"))+
theme_light(base_size = 15) +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
ylab("Percentage reported")+
ggtitle("Reported overall")
ma_data_all_pc_plot
